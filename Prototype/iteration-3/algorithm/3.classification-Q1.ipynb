{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Q1 dataset to the clusters\n",
    "In this file, the preparation for Q1 dataset take place by updating the Q1 dataset created for iteration 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the warnings for presentation of the notebook. During the development, the warnings were not ignored.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import pandas, sklearn model and both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101101 entries, 0 to 101100\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Unnamed: 0           101101 non-null  int64  \n",
      " 1   userID               101101 non-null  int64  \n",
      " 2   companyID            101101 non-null  int64  \n",
      " 3   country              101101 non-null  int64  \n",
      " 4   activity             101101 non-null  int64  \n",
      " 5   event                101101 non-null  float64\n",
      " 6   timestamp            101101 non-null  object \n",
      " 7   page                 101101 non-null  int64  \n",
      " 8   hour                 101101 non-null  int64  \n",
      " 9   day                  101101 non-null  int64  \n",
      " 10  week                 101101 non-null  int64  \n",
      " 11  userCountPerCompany  101101 non-null  int64  \n",
      "dtypes: float64(1), int64(10), object(1)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('final-Q4.csv')\n",
    "df1 = pd.read_csv('cluster-Q1.csv')\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Unnamed: 0           100000 non-null  int64  \n",
      " 1   userID               100000 non-null  int64  \n",
      " 2   companyID            100000 non-null  int64  \n",
      " 3   country              100000 non-null  object \n",
      " 4   activity             100000 non-null  object \n",
      " 5   event                100000 non-null  float64\n",
      " 6   page                 100000 non-null  object \n",
      " 7   timestamp            100000 non-null  object \n",
      " 8   hour                 100000 non-null  int64  \n",
      " 9   day                  100000 non-null  int64  \n",
      " 10  week                 100000 non-null  int64  \n",
      " 11  userCountPerCompany  100000 non-null  int64  \n",
      " 12  cluster              100000 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(4)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, add the cluster from the Q4 data to Q1 dataset by mapping the userID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101101 entries, 0 to 101100\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Unnamed: 0           101101 non-null  int64  \n",
      " 1   userID               101101 non-null  int64  \n",
      " 2   companyID            101101 non-null  int64  \n",
      " 3   country              101101 non-null  int64  \n",
      " 4   activity             101101 non-null  int64  \n",
      " 5   event                101101 non-null  float64\n",
      " 6   timestamp            101101 non-null  object \n",
      " 7   page                 101101 non-null  int64  \n",
      " 8   hour                 101101 non-null  int64  \n",
      " 9   day                  101101 non-null  int64  \n",
      " 10  week                 101101 non-null  int64  \n",
      " 11  userCountPerCompany  101101 non-null  int64  \n",
      " 12  cluster              101101 non-null  int64  \n",
      "dtypes: float64(1), int64(11), object(1)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "mapping = dict(df[['userID', 'cluster']].values)\n",
    "df1['cluster'] = df1[['userID']].userID.map(mapping)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the cluster assigned to Q1 dataset to see the initial amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48282\n",
       "3    31728\n",
       "1    16046\n",
       "2     5045\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these variables to predict which cluster these user belong in Q1: country, activity, page, hour, day, week, event, userCountPerCompany<br>\n",
    "<br>\n",
    "In the below cell, the training and test data are separated by 70% and 30%. This built-in function from sk-learn splits the data set randomly into a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X = df1[['country', 'activity', 'page', 'hour', 'day', 'week', 'event', 'userCountPerCompany']]\n",
    "X = normalize(X)\n",
    "y = df1['cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below random forest model is a built-in function from sk-learn. RF uses randomness, a random_state is set for stability of result. Traditionally, literature suggests 10 more trees to be used in this model. But in this project, we'll use 100 (see n_estimators below). Setting random_state to a fixed value will guarantee that same random numbers are generated each time the code is run. Therefore, the result will be always the same. This is helpful when verifying the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, n_estimators=100)\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below, we're going to evaluate the model using a confusion matrix and calculating accuracy, precision and recall. This is typical for classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14124,    55,     1,   358],\n",
       "       [    5,  4803,     0,     3],\n",
       "       [    0,     2,  1518,     6],\n",
       "       [  320,    34,     2,  9100]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0 prediction</th>\n",
       "      <th>1 prediction</th>\n",
       "      <th>2 prediction</th>\n",
       "      <th>3 prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 actual</th>\n",
       "      <td>14124</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 actual</th>\n",
       "      <td>5</td>\n",
       "      <td>4803</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 actual</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1518</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 actual</th>\n",
       "      <td>320</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>9100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0 prediction  1 prediction  2 prediction  3 prediction\n",
       "0 actual         14124            55             1           358\n",
       "1 actual             5          4803             0             3\n",
       "2 actual             0             2          1518             6\n",
       "3 actual           320            34             2          9100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test) \n",
    "conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "conf_matrix = pd.DataFrame(cm, index=['0 actual', '1 actual', '2 actual', '3 actual'], columns = ['0 prediction', '1 prediction', '2 prediction', '3 prediction']) \n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model has almost 100% precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     14538\n",
      "           1       0.98      1.00      0.99      4811\n",
      "           2       1.00      0.99      1.00      1526\n",
      "           3       0.96      0.96      0.96      9456\n",
      "\n",
      "    accuracy                           0.97     30331\n",
      "   macro avg       0.98      0.98      0.98     30331\n",
      "weighted avg       0.97      0.97      0.97     30331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userID</th>\n",
       "      <th>companyID</th>\n",
       "      <th>country</th>\n",
       "      <th>activity</th>\n",
       "      <th>event</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>page</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>userCountPerCompany</th>\n",
       "      <th>cluster</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-02-05 08:17:01</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2466</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2021-01-05 22:56:21</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3075</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-11 12:56:44</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-03-17 19:24:07</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2040</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-01-05 13:55:09</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  userID  companyID  country  activity  event  \\\n",
       "0           0      32         37        1         1    1.0   \n",
       "1           1     140         41        0         1    3.0   \n",
       "2           2     195          8        1         0    0.0   \n",
       "3           3      19         23        1         1    1.0   \n",
       "4           4      84         17        0         1    2.0   \n",
       "\n",
       "             timestamp  page  hour  day  week  userCountPerCompany  cluster  \\\n",
       "0  2021-02-05 08:17:01     5    11    4     5                 2466        3   \n",
       "1  2021-01-05 22:56:21     5     5    2     1                 3075        1   \n",
       "2  2021-02-11 12:56:44     5    15    3     6                 1027        0   \n",
       "3  2021-03-17 19:24:07     4    22    2    11                 2040        3   \n",
       "4  2021-01-05 13:55:09     2    20    1     1                 1487        0   \n",
       "\n",
       "   predictions  \n",
       "0            3  \n",
       "1            1  \n",
       "2            0  \n",
       "3            3  \n",
       "4            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = rf.predict(X)\n",
    "df1['predictions'] = y_pred2\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we added the prediction back to the Q1 dataframe. When the most common prediction is not the original cluster number itself, then the most common prediction value become the new cluster of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCluster = df1[['userID', 'predictions']]\n",
    "df1['Most common predictions'] = getCluster.groupby('userID')['predictions'].transform(lambda x: x.value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48282\n",
       "3    31728\n",
       "1    16046\n",
       "2     5045\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['new cluster'] = df1.apply(lambda x : x['cluster'] if x['cluster'] == x['Most common predictions'] else x['Most common predictions'], axis=1)\n",
    "df1['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48282\n",
       "3    31728\n",
       "1    16046\n",
       "2     5045\n",
       "Name: new cluster, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['new cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the values of country, activity and page variables and then save the dataset to csv to be further processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country'] = df1['country'].replace({0:'Indonesia', 1:'Turkey'})\n",
    "df1['activity'] = df1['activity'].replace({0:'Page', 1:'Event'})\n",
    "df1['page'] = df1['page'].replace({0:'https://en.wikipedia.org', \n",
    "                                 1: 'https://en.wikipedia.org/wiki/Main_Page',\n",
    "                                 2: 'https://en.wikipedia.org/wiki/Accounting',\n",
    "                                 3: 'https://en.wikipedia.org/wiki/Bookkeeping',\n",
    "                                 4: 'https://en.wikipedia.org/wiki/Financial_technology',\n",
    "                                 5: 'https://en.wikipedia.org/wiki/Financial_services'})\n",
    "df1.to_csv('final-Q1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure that random forest model has the best accuracy, in this section, classification will be done with *KNeightborsClassifier* class from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below, we can see that the KNN model accuracy is less than random forest. Thus, using random forest was indeed a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517424417262866"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
